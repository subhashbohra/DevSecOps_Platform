

---

## 1ï¸âƒ£ Start the meeting with the RIGHT framing (30 seconds)

Say something like this (calm, confident):

> â€œMy goal is to deliver this Airflow + Spark POC end-to-end within the next two weeks and meet every acceptance criterion without rework.
> Iâ€™d like to clarify a few dependencies and standards today so we can move fast and avoid blockers later.â€

This sets you up as **execution-focused**, not confused.

---

## 2ï¸âƒ£ Questions to ask (these will save you DAYS)

### A. Environment & Access (ask FIRST)

These unblock everything else.

1. **Cluster & namespace**

* â€œWhich GKE/GDC cluster and namespaces should I target for this POC?â€
* â€œCan I create namespaces myself, or should I request them via platform?â€

2. **Permissions**

* â€œDo I already have permission to deploy Helm charts and CRDs (for Spark Operator), or do I need platform help?â€
* â€œIs there an existing service account pattern I must follow for Airflow and Spark?â€

3. **Image registry**

* â€œWhich container registry is approved for custom images?â€
* â€œIs image scanning/signing required for POC, or can we keep it minimal?â€

ğŸ‘‰ *Why this matters:* Spark Operator needs CRDs + image pulls. If this isnâ€™t clear, youâ€™ll stall later.

---

### B. Logging & Observability (VERY important)

This is explicitly in acceptance criteria.

Ask **exactly**:

1. **Centralized logging**

* â€œWhat is the standard centralized logging system in GDC for Kubernetes workloads?â€
* â€œAre pod stdout/stderr logs already collected by default?â€

2. **Retention & access**

* â€œHow long are logs retained for ephemeral pods?â€
* â€œWhat is the recommended way for developers to query Spark driver/executor logs?â€

3. **Spark-specific logs**

* â€œIs there an approved object store (GCS / equivalent) for Spark event logs?â€
* â€œIs running a Spark History Server acceptable for this POC, or is log explorer sufficient?â€

ğŸ‘‰ *Why this matters:* This is usually where POCs fail acceptance.

---

### C. ArgoCD & GitOps (donâ€™t assume anything)

Ask these **clearly**:

1. **Repo ownership**

* â€œWhich platform-owned repositories should I use for Airflow, Spark, and test apps?â€
* â€œShould I create new paths or reuse existing ones?â€

2. **ArgoCD pattern**

* â€œAre we using app-of-apps, Helm directly, or Kustomize as the standard?â€
* â€œDo you prefer one ArgoCD app per component or a single umbrella app?â€

3. **Access**

* â€œWill I have write access to ArgoCD applications, or should I submit PRs only?â€

ğŸ‘‰ *Why this matters:* Avoids rework when someone says â€œthis isnâ€™t our GitOps standardâ€.

---

### D. Airflow standards (keep it simple but compliant)

Ask:

1. **Airflow flavor**

* â€œDo we already have a pre-packaged Airflow solution we must use, or can I deploy the official Helm chart for this POC?â€

2. **Executor**

* â€œIs KubernetesExecutor acceptable for this POC?â€

3. **Auth & exposure**

* â€œHow should Airflow UI be exposed â€” internal ingress, gateway, or port-forward for POC?â€

ğŸ‘‰ *Why this matters:* Choosing the wrong executor or exposure method creates churn.

---

### E. Spark POC scope (lock this down early)

Ask:

1. **Job expectations**

* â€œIs a simple Spark job (pi / wordcount) sufficient as long as it runs with 2â€“3 executors?â€

2. **Resource limits**

* â€œAre there quota limits I should stay within for driver/executor pods?â€

3. **Ephemeral requirement**

* â€œJust to confirm â€” executor pods must terminate after job completion, correct?â€

ğŸ‘‰ *Why this matters:* Prevents â€œthis is too basicâ€ feedback later.

---

### F. Demo & Acceptance (THIS MAKES YOU LOOK SMART)

Ask this verbatim:

> â€œAt the end of this POC, what would a *successful demo* look like from your perspective?â€

Then follow with:

* â€œIs a live Airflow DAG trigger â†’ Spark job â†’ logs walkthrough sufficient?â€
* â€œWho needs to sign off on acceptance?â€

ğŸ‘‰ *Why this matters:* You align delivery to **their mental picture of success**.

---

## 3ï¸âƒ£ YES â€” You SHOULD log everything (this protects you)

### âœ… Best practice for your situation

Do **both**:

### 1) Daily or per-meeting **Minutes of Meeting (MoM)**

Send after **every discussion**, even short ones.

**MoM template (copy-paste):**

```
Meeting: Airflow & Spark POC â€“ CLT-71116
Date:
Attendees:

Key Decisions:
- Logging solution:
- ArgoCD repo:
- Airflow deployment approach:
- Spark deployment approach:

Open Questions / Actions:
- [Name] â€“ Action â€“ Due date

Risks / Dependencies:
- e.g., CRD install permission pending
```

Send this by email or Teams â€” this creates an **audit trail**.

---

### 2) One **living Confluence page** (VERY IMPORTANT)

Create a page titled:

> **â€œAirflow & Spark POC on GDC â€“ Execution & Statusâ€**

Sections to include:

1. Scope & Acceptance Criteria (copy from Jira)
2. Architecture Diagram (simple box diagram is fine)
3. Jira Task Breakdown & Status
4. Decisions Log (date-wise)
5. Risks & Mitigations
6. Demo Plan
7. Links (repos, ArgoCD apps, Airflow UI)

ğŸ‘‰ Update this daily or every 2 days.

This makes you look:

* Organized
* Transparent
* In control

And it **protects you** if someone later says â€œthis wasnâ€™t communicatedâ€.

---

## 4ï¸âƒ£ One POWER move before the meeting ends

Close the meeting with this line:

> â€œIâ€™ll send todayâ€™s MoM and create a Confluence page capturing decisions, progress, and risks.
> Please let me know if anyone prefers updates in a different format.â€

This subtly positions you as the **owner** of delivery.

---

## 5ï¸âƒ£ What you should do immediately after TODAYâ€™s meeting

1. Send MoM within **30â€“60 minutes**
2. Create Confluence page same day
3. Create Jira comments summarizing:

   * decisions
   * dependencies
   * next steps

---


